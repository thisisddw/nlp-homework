{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721c57fc-ca3f-4dfe-8243-49afa4c45af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 15:59:53.413257: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-13 15:59:53.588539: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-13 15:59:53.592336: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu/\n",
      "2023-12-13 15:59:53.592360: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-12-13 15:59:54.328200: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu/\n",
      "2023-12-13 15:59:54.328310: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu/\n",
      "2023-12-13 15:59:54.328321: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch_model import TextRNN, TextCNN\n",
    "from cnews_loader import read_vocab, read_category, batch_iter, process_file, build_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3947abec-f7bf-49b5-9c30-0f5f353d9817",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'cnews'\n",
    "train_dir = os.path.join(base_dir, 'train.txt')\n",
    "test_dir = os.path.join(base_dir, 'test.txt')\n",
    "val_dir = os.path.join(base_dir, 'dev.txt')\n",
    "vocab_dir = os.path.join(base_dir, 'vocab.txt')\n",
    "\n",
    "pad_len = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0683f271-1977-4c34-8661-6dd097008a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, Loss, x_val, y_val):\n",
    "    \"\"\"测试集上准确率评估\"\"\"\n",
    "    batch_val = batch_iter(x_val, y_val, 64)\n",
    "    acc = 0\n",
    "    los = 0\n",
    "    for x_batch, y_batch in batch_val:\n",
    "        size = len(x_batch)\n",
    "        x = np.array(x_batch)\n",
    "        y = np.array(y_batch)\n",
    "        x = torch.LongTensor(x).to(device)\n",
    "        y = torch.Tensor(y).to(device)\n",
    "        # y = torch.LongTensor(y)\n",
    "        # x = Variable(x)\n",
    "        # y = Variable(y)\n",
    "        out = model(x)\n",
    "        loss = Loss(out, y)\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        loss_value = np.mean(loss.cpu().detach().numpy())\n",
    "        accracy = np.mean((torch.argmax(out, 1) == torch.argmax(y, 1)).cpu().numpy())\n",
    "        acc +=accracy*size\n",
    "        los +=loss_value*size\n",
    "    return los/len(x_val), acc/len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae742f13-9f1d-4fc5-bd89-1ffdf1a68c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    x_train, y_train = process_file(train_dir, word_to_id, cat_to_id,pad_len)#获取训练数据每个字的id和对应标签的oe-hot形式\n",
    "    x_val, y_val = process_file(val_dir, word_to_id, cat_to_id,pad_len)\n",
    "    #使用LSTM或者CNN\n",
    "    # model = TextRNN()\n",
    "    model = TextCNN()\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    #选择损失函数\n",
    "    Loss = nn.MultiLabelSoftMarginLoss()\n",
    "    # Loss = nn.BCELoss()\n",
    "    # Loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(10):\n",
    "        i = 0\n",
    "        print('epoch:{}'.format(epoch))\n",
    "        batch_train = batch_iter(x_train, y_train,64)\n",
    "        for x_batch, y_batch in batch_train:\n",
    "            i +=1\n",
    "            # print(i)\n",
    "            x = np.array(x_batch)\n",
    "            y = np.array(y_batch)\n",
    "            x = torch.LongTensor(x).to(device)\n",
    "            y = torch.Tensor(y).to(device)\n",
    "            # y = torch.LongTensor(y)\n",
    "            # x = Variable(x)\n",
    "            # y = Variable(y)\n",
    "            out = model(x)\n",
    "            loss = Loss(out,y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 对模型进行验证\n",
    "            if i % 300 == 0:\n",
    "                los, accracy = evaluate(model, Loss, x_val, y_val)\n",
    "                print('loss:{},accracy:{}'.format(los, accracy))\n",
    "                if accracy > best_val_acc:\n",
    "                    torch.save(model.state_dict(), 'model_params.pkl')\n",
    "                    best_val_acc = accracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a360c989-6571-44b3-949c-d57c661e7002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch:0\n",
      "loss:0.2864182671070099,accracy:0.3294\n",
      "loss:0.24473629155158996,accracy:0.4607\n",
      "loss:0.22387070829868316,accracy:0.529\n",
      "loss:0.20646047756671906,accracy:0.5865\n",
      "loss:0.1948151601791382,accracy:0.6224\n",
      "loss:0.18260347797870635,accracy:0.6568\n",
      "loss:0.17390141050815583,accracy:0.6797\n",
      "loss:0.16504904317855834,accracy:0.7038\n",
      "loss:0.1612353448152542,accracy:0.7165\n",
      "epoch:1\n",
      "loss:0.15258612034320831,accracy:0.7308\n",
      "loss:0.15020932745933532,accracy:0.737\n",
      "loss:0.14543523077964782,accracy:0.7521\n",
      "loss:0.14237202477455138,accracy:0.7556\n",
      "loss:0.1391454796552658,accracy:0.7629\n",
      "loss:0.1371999620437622,accracy:0.7641\n",
      "loss:0.13539794983863832,accracy:0.7713\n",
      "loss:0.1338011112332344,accracy:0.7741\n",
      "loss:0.13123095686435698,accracy:0.7777\n",
      "epoch:2\n",
      "loss:0.1280719792366028,accracy:0.7821\n",
      "loss:0.12920602531433106,accracy:0.7805\n",
      "loss:0.12630194010734558,accracy:0.7887\n",
      "loss:0.12476422098875045,accracy:0.7926\n",
      "loss:0.12467464599609375,accracy:0.7937\n",
      "loss:0.12458377424478531,accracy:0.7934\n",
      "loss:0.1226146828174591,accracy:0.7893\n",
      "loss:0.12254210064411164,accracy:0.7953\n",
      "loss:0.1221600760936737,accracy:0.7935\n",
      "epoch:3\n",
      "loss:0.12069660348892212,accracy:0.8019\n",
      "loss:0.11801361985206604,accracy:0.8061\n",
      "loss:0.11925945251584052,accracy:0.8022\n",
      "loss:0.11930828813314438,accracy:0.8015\n",
      "loss:0.1163439260840416,accracy:0.8079\n",
      "loss:0.11836864125728608,accracy:0.8046\n",
      "loss:0.11608029836416245,accracy:0.8011\n",
      "loss:0.11665082633495331,accracy:0.803\n",
      "loss:0.11710126764774323,accracy:0.8026\n",
      "epoch:4\n",
      "loss:0.11770803571939469,accracy:0.8052\n",
      "loss:0.11609735050201415,accracy:0.806\n",
      "loss:0.11441115307807923,accracy:0.806\n",
      "loss:0.1152112184882164,accracy:0.8096\n",
      "loss:0.11608043072223663,accracy:0.8105\n",
      "loss:0.11551201485395432,accracy:0.8096\n",
      "loss:0.11361704905033111,accracy:0.8104\n",
      "loss:0.11303566410541535,accracy:0.8145\n",
      "loss:0.11208285863399506,accracy:0.8147\n",
      "epoch:5\n",
      "loss:0.11355048215389252,accracy:0.8115\n",
      "loss:0.11444322135448456,accracy:0.8073\n",
      "loss:0.11385479602813721,accracy:0.8096\n",
      "loss:0.11100225939750671,accracy:0.8124\n",
      "loss:0.11076062463521957,accracy:0.8152\n",
      "loss:0.11338191448450088,accracy:0.8122\n",
      "loss:0.1128719336271286,accracy:0.8131\n",
      "loss:0.1120794538974762,accracy:0.8169\n",
      "loss:0.11249239594936371,accracy:0.8143\n",
      "epoch:6\n",
      "loss:0.11264615232944489,accracy:0.8135\n",
      "loss:0.10905044912099839,accracy:0.8187\n",
      "loss:0.11083951869010926,accracy:0.8193\n",
      "loss:0.11023047139644623,accracy:0.8159\n",
      "loss:0.11076970362663269,accracy:0.813\n",
      "loss:0.10887577120065689,accracy:0.8248\n",
      "loss:0.1084709247469902,accracy:0.8225\n",
      "loss:0.1091539222240448,accracy:0.8211\n",
      "loss:0.1097426014661789,accracy:0.8179\n",
      "epoch:7\n",
      "loss:0.10964436147212982,accracy:0.8198\n",
      "loss:0.11054689021110535,accracy:0.8206\n",
      "loss:0.10845499758720398,accracy:0.8238\n",
      "loss:0.1099765675663948,accracy:0.8192\n",
      "loss:0.10931475459337235,accracy:0.819\n",
      "loss:0.10795964119434356,accracy:0.8227\n",
      "loss:0.1080898386001587,accracy:0.8219\n",
      "loss:0.10763775565624237,accracy:0.8251\n",
      "loss:0.10858516550064087,accracy:0.8197\n",
      "epoch:8\n",
      "loss:0.10732242918014526,accracy:0.8208\n",
      "loss:0.10840942161083221,accracy:0.8237\n",
      "loss:0.10718349348306656,accracy:0.8276\n",
      "loss:0.10746349917650223,accracy:0.825\n",
      "loss:0.10617128450870514,accracy:0.8258\n",
      "loss:0.10876687395572662,accracy:0.8211\n",
      "loss:0.1078559159040451,accracy:0.8197\n",
      "loss:0.10760530910491943,accracy:0.8235\n",
      "loss:0.106491537463665,accracy:0.8256\n",
      "epoch:9\n",
      "loss:0.1059974458694458,accracy:0.8276\n",
      "loss:0.109211246997118,accracy:0.8236\n",
      "loss:0.10688944563865661,accracy:0.8216\n",
      "loss:0.10583002080917359,accracy:0.8237\n",
      "loss:0.10712385306358338,accracy:0.8224\n",
      "loss:0.10699091144800187,accracy:0.8278\n",
      "loss:0.10764006819725036,accracy:0.8263\n",
      "loss:0.1070421415567398,accracy:0.8237\n",
      "loss:0.10726434407234192,accracy:0.823\n"
     ]
    }
   ],
   "source": [
    "#获取文本的类别及其对应id的字典\n",
    "categories, cat_to_id = read_category()\n",
    "#获取训练文本中所有出现过的字及其所对应的id\n",
    "build_vocab(train_dir, vocab_dir)\n",
    "words, word_to_id = read_vocab(vocab_dir)\n",
    "#获取字数\n",
    "vocab_size = len(words)\n",
    "print('train')\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.4",
   "language": "python",
   "name": "pytorch-1.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
