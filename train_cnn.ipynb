{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721c57fc-ca3f-4dfe-8243-49afa4c45af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 14:48:54.806222: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-12 14:48:54.963564: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-12 14:48:54.967141: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu/\n",
      "2023-12-12 14:48:54.967163: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-12-12 14:48:55.676482: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu/\n",
      "2023-12-12 14:48:55.676583: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu/\n",
      "2023-12-12 14:48:55.676592: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch_model import TextRNN, TextCNN\n",
    "from cnews_loader import read_vocab, read_category, batch_iter, process_file, build_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3947abec-f7bf-49b5-9c30-0f5f353d9817",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'cnews'\n",
    "train_dir = os.path.join(base_dir, 'cnews.train.txt')\n",
    "test_dir = os.path.join(base_dir, 'cnews.test.txt')\n",
    "val_dir = os.path.join(base_dir, 'cnews.val.txt')\n",
    "vocab_dir = os.path.join(base_dir, 'cnews.vocab.txt')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0683f271-1977-4c34-8661-6dd097008a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, Loss, x_val, y_val):\n",
    "    \"\"\"测试集上准确率评估\"\"\"\n",
    "    batch_val = batch_iter(x_val, y_val, 64)\n",
    "    acc = 0\n",
    "    los = 0\n",
    "    for x_batch, y_batch in batch_val:\n",
    "        size = len(x_batch)\n",
    "        x = np.array(x_batch)\n",
    "        y = np.array(y_batch)\n",
    "        x = torch.LongTensor(x).to(device)\n",
    "        y = torch.Tensor(y).to(device)\n",
    "        # y = torch.LongTensor(y)\n",
    "        # x = Variable(x)\n",
    "        # y = Variable(y)\n",
    "        out = model(x)\n",
    "        loss = Loss(out, y)\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        loss_value = np.mean(loss.cpu().detach().numpy())\n",
    "        accracy = np.mean((torch.argmax(out, 1) == torch.argmax(y, 1)).cpu().numpy())\n",
    "        acc +=accracy*size\n",
    "        los +=loss_value*size\n",
    "    return los/len(x_val), acc/len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae742f13-9f1d-4fc5-bd89-1ffdf1a68c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    x_train, y_train = process_file(train_dir, word_to_id, cat_to_id,600)#获取训练数据每个字的id和对应标签的oe-hot形式\n",
    "    x_val, y_val = process_file(val_dir, word_to_id, cat_to_id,600)\n",
    "    #使用LSTM或者CNN\n",
    "    # model = TextRNN()\n",
    "    model = TextCNN()\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    #选择损失函数\n",
    "    Loss = nn.MultiLabelSoftMarginLoss()\n",
    "    # Loss = nn.BCELoss()\n",
    "    # Loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(20):\n",
    "        i = 0\n",
    "        print('epoch:{}'.format(epoch))\n",
    "        batch_train = batch_iter(x_train, y_train,64)\n",
    "        for x_batch, y_batch in batch_train:\n",
    "            i +=1\n",
    "            # print(i)\n",
    "            x = np.array(x_batch)\n",
    "            y = np.array(y_batch)\n",
    "            x = torch.LongTensor(x).to(device)\n",
    "            y = torch.Tensor(y).to(device)\n",
    "            # y = torch.LongTensor(y)\n",
    "            # x = Variable(x)\n",
    "            # y = Variable(y)\n",
    "            out = model(x)\n",
    "            loss = Loss(out,y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 对模型进行验证\n",
    "            if i % 300 == 0:\n",
    "                los, accracy = evaluate(model, Loss, x_val, y_val)\n",
    "                print('loss:{},accracy:{}'.format(los, accracy))\n",
    "                if accracy > best_val_acc:\n",
    "                    torch.save(model.state_dict(), 'model_params_cnn.pkl')\n",
    "                    best_val_acc = accracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a360c989-6571-44b3-949c-d57c661e7002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch:0\n",
      "loss:0.2626219564437866,accracy:0.4482\n",
      "loss:0.21302579765319823,accracy:0.5826\n",
      "epoch:1\n",
      "loss:0.16581347000598906,accracy:0.69\n",
      "loss:0.13692533996105194,accracy:0.763\n",
      "epoch:2\n",
      "loss:0.1138684547662735,accracy:0.8132\n",
      "loss:0.1092594182908535,accracy:0.8184\n",
      "epoch:3\n",
      "loss:0.10215294127464294,accracy:0.837\n",
      "loss:0.09696827182769775,accracy:0.8396\n",
      "epoch:4\n",
      "loss:0.09490450357198715,accracy:0.8474\n",
      "loss:0.09163130110949277,accracy:0.856\n",
      "epoch:5\n",
      "loss:0.08755503225326539,accracy:0.8622\n",
      "loss:0.08077967715263366,accracy:0.8782\n",
      "epoch:6\n",
      "loss:0.08257041132450103,accracy:0.8724\n",
      "loss:0.08029311288595199,accracy:0.8818\n",
      "epoch:7\n",
      "loss:0.08106081169843674,accracy:0.8852\n",
      "loss:0.08329814631044864,accracy:0.8774\n",
      "epoch:8\n",
      "loss:0.07828249506950379,accracy:0.885\n",
      "loss:0.07896101083755493,accracy:0.8838\n",
      "epoch:9\n",
      "loss:0.0765984297990799,accracy:0.889\n",
      "loss:0.08004815601110458,accracy:0.8802\n",
      "epoch:10\n",
      "loss:0.07919044415950775,accracy:0.8874\n",
      "loss:0.07773881826400757,accracy:0.892\n",
      "epoch:11\n",
      "loss:0.07355061296224594,accracy:0.8908\n",
      "loss:0.07573205989450216,accracy:0.8904\n",
      "epoch:12\n",
      "loss:0.07424125344753266,accracy:0.8934\n",
      "loss:0.0744664997369051,accracy:0.8894\n",
      "epoch:13\n",
      "loss:0.07367706772685051,accracy:0.897\n",
      "loss:0.07339270807802677,accracy:0.8994\n",
      "epoch:14\n",
      "loss:0.07385263466835022,accracy:0.8994\n",
      "loss:0.07885572909116745,accracy:0.8944\n",
      "epoch:15\n",
      "loss:0.07412371072024107,accracy:0.8966\n",
      "loss:0.07567319378852844,accracy:0.8946\n",
      "epoch:16\n",
      "loss:0.07327038829326629,accracy:0.901\n",
      "loss:0.070476433801651,accracy:0.9038\n",
      "epoch:17\n",
      "loss:0.07430608969926834,accracy:0.8964\n",
      "loss:0.0730497132986784,accracy:0.9032\n",
      "epoch:18\n",
      "loss:0.07292964472174644,accracy:0.904\n",
      "loss:0.07328106499910354,accracy:0.9026\n",
      "epoch:19\n",
      "loss:0.07085556642413139,accracy:0.9034\n",
      "loss:0.07177426357269287,accracy:0.9042\n"
     ]
    }
   ],
   "source": [
    "#获取文本的类别及其对应id的字典\n",
    "categories, cat_to_id = read_category()\n",
    "#获取训练文本中所有出现过的字及其所对应的id\n",
    "words, word_to_id = read_vocab(vocab_dir)\n",
    "#获取字数\n",
    "vocab_size = len(words)\n",
    "print('train')\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.4",
   "language": "python",
   "name": "pytorch-1.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
