{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721c57fc-ca3f-4dfe-8243-49afa4c45af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 15:51:00.651436: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-13 15:51:00.811854: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-13 15:51:00.815610: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu/\n",
      "2023-12-13 15:51:00.815634: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-12-13 15:51:01.529976: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu/\n",
      "2023-12-13 15:51:01.530098: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu/\n",
      "2023-12-13 15:51:01.530109: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch_model import TextRNN, TextCNN\n",
    "from cnews_loader import read_vocab, read_category, batch_iter, process_file, build_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3947abec-f7bf-49b5-9c30-0f5f353d9817",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'cnews'\n",
    "train_dir = os.path.join(base_dir, 'train.txt')\n",
    "test_dir = os.path.join(base_dir, 'test.txt')\n",
    "val_dir = os.path.join(base_dir, 'dev.txt')\n",
    "vocab_dir = os.path.join(base_dir, 'vocab.txt')\n",
    "\n",
    "pad_len = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0683f271-1977-4c34-8661-6dd097008a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, Loss, x_val, y_val):\n",
    "    \"\"\"测试集上准确率评估\"\"\"\n",
    "    batch_val = batch_iter(x_val, y_val, 64)\n",
    "    acc = 0\n",
    "    los = 0\n",
    "    for x_batch, y_batch in batch_val:\n",
    "        size = len(x_batch)\n",
    "        x = np.array(x_batch)\n",
    "        y = np.array(y_batch)\n",
    "        x = torch.LongTensor(x).to(device)\n",
    "        y = torch.Tensor(y).to(device)\n",
    "        # y = torch.LongTensor(y)\n",
    "        # x = Variable(x)\n",
    "        # y = Variable(y)\n",
    "        out = model(x)\n",
    "        loss = Loss(out, y)\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        loss_value = np.mean(loss.cpu().detach().numpy())\n",
    "        accracy = np.mean((torch.argmax(out, 1) == torch.argmax(y, 1)).cpu().numpy())\n",
    "        acc +=accracy*size\n",
    "        los +=loss_value*size\n",
    "    return los/len(x_val), acc/len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae742f13-9f1d-4fc5-bd89-1ffdf1a68c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    x_train, y_train = process_file(train_dir, word_to_id, cat_to_id,pad_len)#获取训练数据每个字的id和对应标签的oe-hot形式\n",
    "    x_val, y_val = process_file(val_dir, word_to_id, cat_to_id,pad_len)\n",
    "    #使用LSTM或者CNN\n",
    "    model = TextRNN()\n",
    "    \n",
    "    model.to(device)\n",
    "    # model = TextCNN()\n",
    "    \n",
    "    #选择损失函数\n",
    "    Loss = nn.MultiLabelSoftMarginLoss()\n",
    "    # Loss = nn.BCELoss()\n",
    "    # Loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(10):\n",
    "        i = 0\n",
    "        print('epoch:{}'.format(epoch))\n",
    "        batch_train = batch_iter(x_train, y_train,64)\n",
    "        for x_batch, y_batch in batch_train:\n",
    "            i +=1\n",
    "            # print(i)\n",
    "            x = np.array(x_batch)\n",
    "            y = np.array(y_batch)\n",
    "            x = torch.LongTensor(x).to(device)\n",
    "            y = torch.Tensor(y).to(device)\n",
    "            # y = torch.LongTensor(y)\n",
    "            # x = Variable(x)\n",
    "            # y = Variable(y)\n",
    "            out = model(x)\n",
    "            loss = Loss(out,y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 对模型进行验证\n",
    "            if i % 300 == 0:\n",
    "                los, accracy = evaluate(model, Loss, x_val, y_val)\n",
    "                print('loss:{},accracy:{}'.format(los, accracy))\n",
    "                if accracy > best_val_acc:\n",
    "                    torch.save(model.state_dict(), 'model_params.pkl')\n",
    "                    best_val_acc = accracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a360c989-6571-44b3-949c-d57c661e7002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.7110180891036987,accracy:0.4292\n",
      "loss:0.7002470533370971,accracy:0.5507\n",
      "loss:0.6924094657897949,accracy:0.6278\n",
      "loss:0.6883277956008911,accracy:0.6716\n",
      "loss:0.6867353130340577,accracy:0.6846\n",
      "loss:0.684760183429718,accracy:0.7039\n",
      "loss:0.6820969957351685,accracy:0.7305\n",
      "loss:0.6805212617874146,accracy:0.7462\n",
      "loss:0.6795818076133728,accracy:0.7574\n",
      "epoch:1\n",
      "loss:0.6779771144866943,accracy:0.7727\n",
      "loss:0.6792295835494995,accracy:0.7596\n",
      "loss:0.6767408140182495,accracy:0.7852\n",
      "loss:0.6763853832244873,accracy:0.7868\n",
      "loss:0.6766004669189453,accracy:0.7867\n",
      "loss:0.675402562904358,accracy:0.7966\n",
      "loss:0.6748628734588623,accracy:0.8037\n",
      "loss:0.6745181085586548,accracy:0.8072\n",
      "loss:0.674998116493225,accracy:0.802\n",
      "epoch:2\n",
      "loss:0.6739078409194946,accracy:0.8136\n",
      "loss:0.673659796333313,accracy:0.8142\n",
      "loss:0.6731851741790772,accracy:0.8193\n",
      "loss:0.6729810678482055,accracy:0.8229\n",
      "loss:0.6738767807006836,accracy:0.8117\n",
      "loss:0.6731948491096497,accracy:0.82\n",
      "loss:0.6727128234863281,accracy:0.8241\n",
      "loss:0.6727243025779724,accracy:0.8245\n",
      "loss:0.6724159646987915,accracy:0.8265\n",
      "epoch:3\n",
      "loss:0.6717180348396301,accracy:0.8351\n",
      "loss:0.6722736448287964,accracy:0.8274\n",
      "loss:0.6723168991088867,accracy:0.8271\n",
      "loss:0.671917174911499,accracy:0.8307\n",
      "loss:0.6715086742401123,accracy:0.8356\n",
      "loss:0.6713268834114074,accracy:0.8368\n",
      "loss:0.671783242893219,accracy:0.8332\n",
      "loss:0.6717983015060425,accracy:0.8328\n",
      "loss:0.6719996552467347,accracy:0.8298\n",
      "epoch:4\n",
      "loss:0.6710857391357422,accracy:0.8393\n",
      "loss:0.6712458953857422,accracy:0.8385\n",
      "loss:0.6709829299926758,accracy:0.8408\n",
      "loss:0.6706715433120728,accracy:0.8438\n",
      "loss:0.6713710378646851,accracy:0.8378\n",
      "loss:0.6705454521179199,accracy:0.8466\n",
      "loss:0.6701417930603027,accracy:0.8494\n",
      "loss:0.6704559834480286,accracy:0.8456\n",
      "loss:0.6704828889846802,accracy:0.8462\n",
      "epoch:5\n",
      "loss:0.6704845670700074,accracy:0.8452\n",
      "loss:0.6706342348098755,accracy:0.8443\n",
      "loss:0.6699164732933044,accracy:0.8501\n",
      "loss:0.6704682705879211,accracy:0.8455\n",
      "loss:0.6706017284393311,accracy:0.8445\n",
      "loss:0.6703560137748719,accracy:0.848\n",
      "loss:0.6698538812637329,accracy:0.8521\n",
      "loss:0.670005251789093,accracy:0.8503\n",
      "loss:0.670424444770813,accracy:0.846\n",
      "epoch:6\n",
      "loss:0.6698321895599365,accracy:0.8526\n",
      "loss:0.6699759618759156,accracy:0.8505\n",
      "loss:0.6697153393745422,accracy:0.8531\n",
      "loss:0.6700603601455688,accracy:0.8502\n",
      "loss:0.6696733619689942,accracy:0.8544\n",
      "loss:0.6694781497955322,accracy:0.8559\n",
      "loss:0.6700138877868652,accracy:0.8506\n",
      "loss:0.6697452450752258,accracy:0.8536\n",
      "loss:0.6691341520309448,accracy:0.8594\n",
      "epoch:7\n",
      "loss:0.6696598474502563,accracy:0.8538\n",
      "loss:0.6691850089073181,accracy:0.8598\n",
      "loss:0.6691560577392578,accracy:0.8583\n",
      "loss:0.6693322982788086,accracy:0.8582\n",
      "loss:0.6689678037643433,accracy:0.8618\n",
      "loss:0.6689047280311584,accracy:0.8612\n",
      "loss:0.6691074649810791,accracy:0.8595\n",
      "loss:0.6691453060150147,accracy:0.8597\n",
      "loss:0.6693140886306763,accracy:0.8575\n",
      "epoch:8\n",
      "loss:0.6692067603111267,accracy:0.859\n",
      "loss:0.6688964772224426,accracy:0.8627\n",
      "loss:0.6686405917167664,accracy:0.8646\n",
      "loss:0.6688703084945679,accracy:0.8611\n",
      "loss:0.6691030420303344,accracy:0.8597\n",
      "loss:0.6687493726730347,accracy:0.863\n",
      "loss:0.6689689744949341,accracy:0.8606\n",
      "loss:0.6688702318191528,accracy:0.8617\n",
      "loss:0.6684874429702758,accracy:0.8652\n",
      "epoch:9\n",
      "loss:0.668623115158081,accracy:0.865\n",
      "loss:0.6687305729866028,accracy:0.8632\n",
      "loss:0.6684522126197815,accracy:0.8658\n",
      "loss:0.6685062828063965,accracy:0.8655\n",
      "loss:0.6690120076179504,accracy:0.8608\n",
      "loss:0.6686625240325927,accracy:0.8639\n",
      "loss:0.6683996808052063,accracy:0.8665\n",
      "loss:0.6684927830696106,accracy:0.8653\n",
      "loss:0.6693433555603028,accracy:0.8582\n"
     ]
    }
   ],
   "source": [
    "#获取文本的类别及其对应id的字典\n",
    "categories, cat_to_id = read_category()\n",
    "#获取训练文本中所有出现过的字及其所对应的id\n",
    "build_vocab(train_dir, vocab_dir)\n",
    "words, word_to_id = read_vocab(vocab_dir)\n",
    "#获取字数\n",
    "vocab_size = len(words)\n",
    "print('train')\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.4",
   "language": "python",
   "name": "pytorch-1.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
