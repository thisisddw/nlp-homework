{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721c57fc-ca3f-4dfe-8243-49afa4c45af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 17:29:36.390132: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-11 17:29:36.555300: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-11 17:29:36.559090: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu/\n",
      "2023-12-11 17:29:36.559116: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-12-11 17:29:37.284202: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu/\n",
      "2023-12-11 17:29:37.284374: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu/\n",
      "2023-12-11 17:29:37.284386: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch_model import TextRNN, TextCNN\n",
    "from cnews_loader import read_vocab, read_category, batch_iter, process_file, build_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84412a4a-0d77-43e6-aedf-610d08e5336e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=10, out_features=10, bias=False)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = 'cpu'\n",
    "\n",
    "x = torch.randn(1, 10).to(device)\n",
    "\n",
    "# module\n",
    "lin = nn.Linear(10, 10, bias=False).to(device)\n",
    "out = lin(x)\n",
    "print(lin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3947abec-f7bf-49b5-9c30-0f5f353d9817",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'cnews'\n",
    "train_dir = os.path.join(base_dir, 'cnews.train.txt')\n",
    "test_dir = os.path.join(base_dir, 'cnews.test.txt')\n",
    "val_dir = os.path.join(base_dir, 'cnews.val.txt')\n",
    "vocab_dir = os.path.join(base_dir, 'cnews.vocab.txt')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0683f271-1977-4c34-8661-6dd097008a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, Loss, x_val, y_val):\n",
    "    \"\"\"测试集上准确率评估\"\"\"\n",
    "    batch_val = batch_iter(x_val, y_val, 64)\n",
    "    acc = 0\n",
    "    los = 0\n",
    "    for x_batch, y_batch in batch_val:\n",
    "        size = len(x_batch)\n",
    "        x = np.array(x_batch)\n",
    "        y = np.array(y_batch)\n",
    "        x = torch.LongTensor(x).to(device)\n",
    "        y = torch.Tensor(y).to(device)\n",
    "        # y = torch.LongTensor(y)\n",
    "        # x = Variable(x)\n",
    "        # y = Variable(y)\n",
    "        out = model(x)\n",
    "        loss = Loss(out, y)\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        loss_value = np.mean(loss.cpu().detach().numpy())\n",
    "        accracy = np.mean((torch.argmax(out, 1) == torch.argmax(y, 1)).cpu().numpy())\n",
    "        acc +=accracy*size\n",
    "        los +=loss_value*size\n",
    "    return los/len(x_val), acc/len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae742f13-9f1d-4fc5-bd89-1ffdf1a68c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    x_train, y_train = process_file(train_dir, word_to_id, cat_to_id,600)#获取训练数据每个字的id和对应标签的oe-hot形式\n",
    "    x_val, y_val = process_file(val_dir, word_to_id, cat_to_id,600)\n",
    "    #使用LSTM或者CNN\n",
    "    model = TextRNN()\n",
    "    \n",
    "    model.to(device)\n",
    "    # model = TextCNN()\n",
    "    \n",
    "    #选择损失函数\n",
    "    Loss = nn.MultiLabelSoftMarginLoss()\n",
    "    # Loss = nn.BCELoss()\n",
    "    # Loss = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(20):\n",
    "        i = 0\n",
    "        print('epoch:{}'.format(epoch))\n",
    "        batch_train = batch_iter(x_train, y_train,64)\n",
    "        for x_batch, y_batch in batch_train:\n",
    "            i +=1\n",
    "            # print(i)\n",
    "            x = np.array(x_batch)\n",
    "            y = np.array(y_batch)\n",
    "            x = torch.LongTensor(x).to(device)\n",
    "            y = torch.Tensor(y).to(device)\n",
    "            # y = torch.LongTensor(y)\n",
    "            # x = Variable(x)\n",
    "            # y = Variable(y)\n",
    "            out = model(x)\n",
    "            loss = Loss(out,y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 对模型进行验证\n",
    "            if i % 90 == 0:\n",
    "                los, accracy = evaluate(model, Loss, x_val, y_val)\n",
    "                print('loss:{},accracy:{}'.format(los, accracy))\n",
    "                if accracy > best_val_acc:\n",
    "                    torch.save(model.state_dict(), 'model_params.pkl')\n",
    "                    best_val_acc = accracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a360c989-6571-44b3-949c-d57c661e7002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "epoch:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.7233162692070008,accracy:0.2612\n",
      "loss:0.718931548500061,accracy:0.3282\n",
      "loss:0.7176477731704712,accracy:0.3378\n",
      "loss:0.7192708904266357,accracy:0.326\n",
      "loss:0.7134006710052491,accracy:0.3968\n",
      "loss:0.7138477840423584,accracy:0.3802\n",
      "loss:0.7150819551467895,accracy:0.3692\n",
      "loss:0.7125554258346558,accracy:0.4092\n",
      "epoch:1\n",
      "loss:0.7114644678115845,accracy:0.4132\n",
      "loss:0.7093504576683044,accracy:0.4318\n",
      "loss:0.710750887966156,accracy:0.4176\n",
      "loss:0.7125651340484619,accracy:0.409\n",
      "loss:0.7235299991607667,accracy:0.2756\n",
      "loss:0.7187762597084045,accracy:0.3322\n",
      "loss:0.7172029609680176,accracy:0.3538\n",
      "loss:0.7128728792190552,accracy:0.403\n",
      "epoch:2\n",
      "loss:0.7116015760421753,accracy:0.4178\n",
      "loss:0.710459390258789,accracy:0.428\n",
      "loss:0.7096115100860596,accracy:0.4424\n",
      "loss:0.711233701992035,accracy:0.4314\n",
      "loss:0.7059494918823243,accracy:0.4812\n",
      "loss:0.7041563882827758,accracy:0.5056\n",
      "loss:0.7035351189613342,accracy:0.5106\n",
      "loss:0.7010683180809021,accracy:0.538\n",
      "epoch:3\n",
      "loss:0.7320642203330994,accracy:0.2034\n",
      "loss:0.7225875356674194,accracy:0.3024\n",
      "loss:0.7191555561065673,accracy:0.3324\n",
      "loss:0.720793816947937,accracy:0.3172\n",
      "loss:0.7178492033958435,accracy:0.3526\n",
      "loss:0.7161642726898193,accracy:0.368\n",
      "loss:0.7174369688034058,accracy:0.3542\n",
      "loss:0.7159852741241455,accracy:0.371\n",
      "epoch:4\n",
      "loss:0.7124538487434388,accracy:0.4066\n",
      "loss:0.7090895494461059,accracy:0.4384\n",
      "loss:0.7058921520233155,accracy:0.4722\n",
      "loss:0.7074665088653564,accracy:0.4616\n",
      "loss:0.7070864351272583,accracy:0.4654\n",
      "loss:0.707124503326416,accracy:0.4668\n",
      "loss:0.7070482562065125,accracy:0.468\n",
      "loss:0.7051507963180542,accracy:0.4888\n",
      "epoch:5\n",
      "loss:0.7112795340538025,accracy:0.4172\n",
      "loss:0.7028733741760254,accracy:0.515\n",
      "loss:0.7009606197357178,accracy:0.532\n",
      "loss:0.7009782125473022,accracy:0.5358\n",
      "loss:0.7016885130882263,accracy:0.5244\n",
      "loss:0.7075571689605713,accracy:0.4644\n",
      "loss:0.7040708480834961,accracy:0.506\n",
      "loss:0.705622066783905,accracy:0.4858\n",
      "epoch:6\n",
      "loss:0.7054770649909973,accracy:0.487\n",
      "loss:0.7055212652206421,accracy:0.4882\n",
      "loss:0.7043442262649536,accracy:0.4948\n",
      "loss:0.7041793907165528,accracy:0.5038\n",
      "loss:0.7014478183746338,accracy:0.5278\n",
      "loss:0.6994785966873169,accracy:0.5524\n",
      "loss:0.6978373788833618,accracy:0.5712\n",
      "loss:0.6986173370361328,accracy:0.5604\n",
      "epoch:7\n",
      "loss:0.6964831297874451,accracy:0.5876\n",
      "loss:0.6981164541244507,accracy:0.5666\n",
      "loss:0.6953511405944824,accracy:0.591\n",
      "loss:0.6932642587661744,accracy:0.6174\n",
      "loss:0.6932252458572388,accracy:0.6146\n",
      "loss:0.7023519680023194,accracy:0.5168\n",
      "loss:0.6971541550636291,accracy:0.5746\n",
      "loss:0.6958063239097595,accracy:0.5864\n",
      "epoch:8\n",
      "loss:0.694048113822937,accracy:0.6064\n",
      "loss:0.6955076086044312,accracy:0.592\n",
      "loss:0.6971866399765014,accracy:0.5782\n",
      "loss:0.7263946519851685,accracy:0.272\n",
      "loss:0.7126034713745117,accracy:0.4084\n",
      "loss:0.7082483452796936,accracy:0.4582\n",
      "loss:0.7073919576644897,accracy:0.4618\n",
      "loss:0.7087189896583557,accracy:0.45\n",
      "epoch:9\n",
      "loss:0.7031172212600708,accracy:0.5112\n",
      "loss:0.7035040662765503,accracy:0.5104\n",
      "loss:0.7030493844985962,accracy:0.509\n",
      "loss:0.7015618093490601,accracy:0.5256\n",
      "loss:0.7041508574485779,accracy:0.5012\n",
      "loss:0.7013515132904052,accracy:0.53\n",
      "loss:0.7007828659057617,accracy:0.5336\n",
      "loss:0.7000853605270386,accracy:0.5436\n",
      "epoch:10\n",
      "loss:0.6974298879623413,accracy:0.5698\n",
      "loss:0.6983854516029357,accracy:0.5632\n",
      "loss:0.6964258198738098,accracy:0.584\n",
      "loss:0.6964090584754944,accracy:0.5854\n",
      "loss:0.6973903396606446,accracy:0.5738\n",
      "loss:0.6954164478302002,accracy:0.5964\n",
      "loss:0.6930722381591797,accracy:0.6218\n",
      "loss:0.6932870383262635,accracy:0.6188\n",
      "epoch:11\n",
      "loss:0.6927726713180542,accracy:0.6206\n",
      "loss:0.6933328598976135,accracy:0.614\n",
      "loss:0.6926066570281982,accracy:0.622\n",
      "loss:0.6915901330947876,accracy:0.633\n",
      "loss:0.692785763835907,accracy:0.6226\n",
      "loss:0.690705673789978,accracy:0.6412\n",
      "loss:0.6903646224021912,accracy:0.646\n",
      "loss:0.68919446144104,accracy:0.656\n",
      "epoch:12\n",
      "loss:0.6872895092010498,accracy:0.6778\n",
      "loss:0.6906835929870605,accracy:0.6406\n",
      "loss:0.6895229175567626,accracy:0.65\n",
      "loss:0.6898516745567321,accracy:0.6484\n",
      "loss:0.6874276545524597,accracy:0.6724\n",
      "loss:0.6884143304824829,accracy:0.665\n",
      "loss:0.689946367263794,accracy:0.6486\n",
      "loss:0.688351759815216,accracy:0.6632\n",
      "epoch:13\n",
      "loss:0.6884110553741455,accracy:0.6632\n",
      "loss:0.6883427081108093,accracy:0.6646\n",
      "loss:0.6876538663864136,accracy:0.671\n",
      "loss:0.6938296720504761,accracy:0.6072\n",
      "loss:0.6915864727020263,accracy:0.6296\n",
      "loss:0.6897828394889831,accracy:0.6506\n",
      "loss:0.6879172357559205,accracy:0.6672\n",
      "loss:0.6890996438980103,accracy:0.6562\n",
      "epoch:14\n",
      "loss:0.6898027263641358,accracy:0.649\n",
      "loss:0.6892374063491822,accracy:0.654\n",
      "loss:0.6887343849182129,accracy:0.6612\n",
      "loss:0.6878570297241211,accracy:0.67\n",
      "loss:0.6874238525390625,accracy:0.6742\n",
      "loss:0.6874832289695739,accracy:0.6746\n",
      "loss:0.6872124305725098,accracy:0.675\n",
      "loss:0.6853894508361816,accracy:0.6932\n",
      "epoch:15\n",
      "loss:0.6864376949310302,accracy:0.6862\n",
      "loss:0.6860260986328125,accracy:0.6898\n",
      "loss:0.6866020316123962,accracy:0.6838\n",
      "loss:0.6849991635322571,accracy:0.6964\n",
      "loss:0.685517110824585,accracy:0.6924\n",
      "loss:0.6829375419616699,accracy:0.7204\n",
      "loss:0.6819190214157105,accracy:0.73\n",
      "loss:0.6830312512397766,accracy:0.7192\n",
      "epoch:16\n",
      "loss:0.6840618228912354,accracy:0.7074\n",
      "loss:0.68366233253479,accracy:0.7122\n",
      "loss:0.6874204254150391,accracy:0.6722\n",
      "loss:0.6868093440055847,accracy:0.6798\n",
      "loss:0.6846046564102173,accracy:0.7032\n",
      "loss:0.6849935897827149,accracy:0.697\n",
      "loss:0.684528897857666,accracy:0.704\n",
      "loss:0.6826688493728638,accracy:0.7248\n",
      "epoch:17\n",
      "loss:0.6824815151214599,accracy:0.726\n",
      "loss:0.6832218315124512,accracy:0.7172\n",
      "loss:0.6831496658325196,accracy:0.7176\n",
      "loss:0.682765116596222,accracy:0.7206\n",
      "loss:0.6861537055969238,accracy:0.6862\n",
      "loss:0.6833287322044372,accracy:0.7162\n",
      "loss:0.6825343661308289,accracy:0.7238\n",
      "loss:0.7034032371520996,accracy:0.5122\n",
      "epoch:18\n",
      "loss:0.6824083410263061,accracy:0.7258\n",
      "loss:0.6829019198417664,accracy:0.7202\n",
      "loss:0.6880387316703797,accracy:0.6676\n",
      "loss:0.6873555583000183,accracy:0.6748\n",
      "loss:0.6843347088813782,accracy:0.7058\n",
      "loss:0.682913415145874,accracy:0.721\n",
      "loss:0.6867915622711182,accracy:0.6808\n",
      "loss:0.6851605409622192,accracy:0.6988\n",
      "epoch:19\n",
      "loss:0.6840063995361328,accracy:0.7102\n",
      "loss:0.6838996917724609,accracy:0.7108\n",
      "loss:0.6836820156097412,accracy:0.7126\n",
      "loss:0.6851529994964599,accracy:0.6962\n",
      "loss:0.6826869808197021,accracy:0.724\n",
      "loss:0.6832448205947876,accracy:0.7168\n",
      "loss:0.6837570236206054,accracy:0.7106\n",
      "loss:0.6829834776878357,accracy:0.7186\n",
      "epoch:20\n",
      "loss:0.6832450510978699,accracy:0.7154\n",
      "loss:0.6810579301834107,accracy:0.739\n",
      "loss:0.6810428020477295,accracy:0.7406\n",
      "loss:0.682897970199585,accracy:0.7188\n",
      "loss:0.6810587177276611,accracy:0.7386\n",
      "loss:0.6882126220703125,accracy:0.6636\n",
      "loss:0.683710178565979,accracy:0.7126\n",
      "loss:0.6806119506835937,accracy:0.7422\n",
      "epoch:21\n",
      "loss:0.6837795641899109,accracy:0.712\n",
      "loss:0.6857563556671142,accracy:0.693\n",
      "loss:0.6824352237701417,accracy:0.7244\n",
      "loss:0.6826419732093811,accracy:0.7216\n",
      "loss:0.6816635182380676,accracy:0.7326\n",
      "loss:0.679244010257721,accracy:0.758\n",
      "loss:0.6798253636360169,accracy:0.7524\n",
      "loss:0.6788364274024964,accracy:0.7614\n",
      "epoch:22\n",
      "loss:0.6791620604515076,accracy:0.7572\n",
      "loss:0.6789109533309936,accracy:0.761\n",
      "loss:0.6799991954803467,accracy:0.7496\n",
      "loss:0.6804310408592225,accracy:0.747\n",
      "loss:0.6798718905448914,accracy:0.7488\n",
      "loss:0.6784742896080017,accracy:0.7638\n",
      "loss:0.6778948049545288,accracy:0.7712\n",
      "loss:0.6780269231796264,accracy:0.7692\n",
      "epoch:23\n",
      "loss:0.6806560220718384,accracy:0.744\n",
      "loss:0.6786681089401245,accracy:0.7658\n",
      "loss:0.6797170557022095,accracy:0.7514\n",
      "loss:0.6797208038330078,accracy:0.7504\n",
      "loss:0.6784534344673157,accracy:0.764\n",
      "loss:0.6779392307281494,accracy:0.7702\n",
      "loss:0.6773473371505737,accracy:0.776\n",
      "loss:0.6802936855316162,accracy:0.7458\n",
      "epoch:24\n",
      "loss:0.6775622909545899,accracy:0.7732\n",
      "loss:0.6796017944335937,accracy:0.7544\n",
      "loss:0.6779893314361572,accracy:0.7696\n",
      "loss:0.679216583442688,accracy:0.7578\n",
      "loss:0.6791492477416993,accracy:0.7588\n",
      "loss:0.6783896423339844,accracy:0.766\n",
      "loss:0.6896232038497925,accracy:0.6522\n",
      "loss:0.6814639159202576,accracy:0.733\n",
      "epoch:25\n",
      "loss:0.6796614534378052,accracy:0.753\n",
      "loss:0.6799436065673828,accracy:0.7514\n",
      "loss:0.679431746006012,accracy:0.7552\n",
      "loss:0.681366282749176,accracy:0.7356\n",
      "loss:0.6795015170097352,accracy:0.7544\n",
      "loss:0.6793221817016601,accracy:0.758\n",
      "loss:0.6811426259994506,accracy:0.7394\n",
      "loss:0.68106469039917,accracy:0.7374\n",
      "epoch:26\n",
      "loss:0.679507119846344,accracy:0.7534\n",
      "loss:0.6794576526641846,accracy:0.7558\n",
      "loss:0.6798956920623779,accracy:0.7492\n",
      "loss:0.6808319114685059,accracy:0.7414\n",
      "loss:0.6793285801887512,accracy:0.7548\n",
      "loss:0.6793735759735108,accracy:0.7558\n",
      "loss:0.6790280373573303,accracy:0.7594\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2787/3431870635.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2787/2448603327.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# x = Variable(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# y = Variable(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/torch_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# batch_size x text_len x embedding_size 64*600*64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# text_len x batch_size x embedding_size 600*64*64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#x为600*64*256, h_n为2*64*128 lstm_out       Sentence_length * Batch_size * (hidden_layers * 2 [bio-direct]) h_n           （num_layers * 2） * Batch_size * hidden_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mfinal_feature_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mfeature_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_feature_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_feature_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#64*256 Batch_size * (hidden_size * hidden_layers * 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch-1.4/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 559\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#获取文本的类别及其对应id的字典\n",
    "categories, cat_to_id = read_category()\n",
    "#获取训练文本中所有出现过的字及其所对应的id\n",
    "words, word_to_id = read_vocab(vocab_dir)\n",
    "#获取字数\n",
    "vocab_size = len(words)\n",
    "print('train')\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.4",
   "language": "python",
   "name": "pytorch-1.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
